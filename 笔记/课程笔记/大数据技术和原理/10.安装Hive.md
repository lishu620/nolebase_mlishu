1.上传HIVE包到/opt/software目录并解压
  tar -zxvf apache-hive-1.2.1-bin.tar.gz -C /opt/modules/
2.修改路径（可选操作）
   mv /opt/modules/apache-hive-1.2.1-bin/  /opt/modules/hive
3.将hIVE下的bin目录加入到/etc/profile中（可选操作）
  export  HIVE_HOME=/opt/modules/hive
  export  PATH=$PATH:$HIVE_HOME/bin
4.配置HIVE
  cd /opt/modules/hive/conf/
-------------------------------------------------
  cp hive-default.xml.template hive-site.xml
  ----------------------------------------------
  sudo  vim  hive-site.xml
```
<configuration>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>root</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>123456</value>
    </property>
	<property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:mysql://gyy1:3306/gyyy?createDatabaseIfNotExist=true&amp;useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
    </property>
</configuration>
```


注意：把mysql的连接驱动拷贝到hive/lib下。一定注意和你的mysql版本匹配
7.故障解晰
  1）如果出现提示权限不够，用sudo chown -R hadoop:hadoop  /opt/modules
  2）如果HIVE在启动时报Establishing SSL connection without server's identity verification is not 等信息，只需要将配置文件里
  <value>jdbc:mysql://NN1:3306/mysql?createDatabaseIfNotExist=true&amp;useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false</value>


  HIVE创建内部数据表命令
  create table t_order(
  id int,produce_id string,number int,amount double)
  row format delimited
  fields terminated by ','
  ;

 HIVE创建外部数据表命令
 create  external table t_order(
  id int,produce_id string,number int,amount double)
  row format delimited
  fields terminated by ','
  location '/user/t2'
  ;
内部表和外部表的区别：
内部表数据由Hive自身管理，外部表数据由HDFS管理；
内部表数据存储的位置是hive.metastore.warehouse.dir（默认：/user/hive/warehouse），外部表数据的存储位置由自己制定；
删除内部表会直接删除元数据（metadata）及存储数据；删除外部表仅仅会删除元数据，HDFS上的文件并不会被删除；
对内部表的修改会将修改直接同步给元数据，而对外部表的表结构和分区进行修改，则需要修复（MSCK REPAIR TABLE table_name;）

  内部表/user/hive/warehouse
  外部表/AAAA/DATA

 create table t(
  id int,produce_id string,number int,amount double)
  row format delimited
  fields terminated by ','
  ;

hive连接成功通过以下几个表来存储信息
可以通过DBS 、TBLS、COLUMNS_V2、SDS这几张表来查看元数据信息
  DBS 存放的数据库的元数据信息
  TBLS存放的tables表信息
  COLUMNS表存放的是列字段信息3
  SDS表存放的HDFS里的位置信息
