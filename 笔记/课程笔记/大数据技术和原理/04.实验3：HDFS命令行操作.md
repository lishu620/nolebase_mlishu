### 实验目标
- 掌握 HDFS 的基本命令（上传、下载、查看、创建目录、删除等）
- 理解 HDFS 的目录结构与权限管理
- 能够通过命令行操作 HDFS 中的文件

---

## 📘 实验步骤与命令解析

### 1. **查看 HDFS 文件内容**
```bash
hadoop fs -cat /file1.txt
```
- 查看 HDFS 根目录下 `file1.txt` 的内容。

---

### 2. **查看文件详细信息**
```bash
hadoop fs -ls /file1.txt
```
- 显示文件的权限、副本数、所有者、大小、修改时间等。

---

### 3. **在本地创建文件**
```bash
echo ‘hello world!’ > /tmp/file2.txt
echo ‘hello hadoop!’ > /tmp/file3.txt
```
- 在本地 `/tmp` 目录下创建两个文本文件。

---

### 4. **在 HDFS 中创建目录**
```bash
hadoop fs -mkdir /dir1
hadoop fs -mkdir /dir1/dir2
```
- 创建多级目录结构。

---

### 5. **上传文件到 HDFS**
```bash
hadoop fs -put /tmp/file2.txt /dir1/
hadoop fs -put /tmp/file3.txt /dir1/dir2/
```
- 将本地文件上传到 HDFS 指定目录。

---

### 6. **递归查看目录结构**
```bash
hadoop fs -ls -R /dir1
```
- 递归列出 `/dir1` 目录下的所有文件和子目录。

---

### 7. **创建空文件**
```bash
hadoop fs -touchz /dir1/dir2/file4.txt
```
- 在 HDFS 中创建一个空文件。

---

### 8. **删除文件**
```bash
hadoop fs -rm /dir1/dir2/file4.txt
```
- 删除 HDFS 中的指定文件。

---

### 9. **从 HDFS 下载文件到本地**
```bash
hadoop fs -get /dir1/dir2/file3.txt /tmp/file3.txt
```
- 如果本地文件已存在，会提示 `File exists`。

---

### 10. **追加本地文件内容并覆盖上传到 HDFS**
```bash
cat /tmp/file1.txt >> /tmp/file3.txt
hadoop fs -put -f /tmp/file3.txt /dir1/dir2/file3.txt
```
- 将 `file1.txt` 内容追加到 `file3.txt`，然后强制上传到 HDFS。

---

### 11. **查看更新后的 HDFS 文件内容**
```bash
hadoop fs -cat /dir1/dir2/file3.txt
```
- 显示合并后的文件内容。

---

## 🧠 知识点总结
| 命令 | 功能 |
|------|------|
| `hadoop fs -cat` | 查看文件内容 |
| `hadoop fs -ls` | 列出文件信息 |
| `hadoop fs -mkdir` | 创建目录 |
| `hadoop fs -put` | 上传文件 |
| `hadoop fs -get` | 下载文件 |
| `hadoop fs -rm` | 删除文件 |
| `hadoop fs -touchz` | 创建空文件 |
| `hadoop fs -ls -R` | 递归列出目录结构 |
| `-f` 参数 | 强制覆盖已存在的文件 |

---

## 📌 注意事项
- 使用 `-put -f` 可以覆盖 HDFS 上已存在的文件。
- 删除文件前确认路径，HDFS 默认不启用回收站（Trash）。
- 使用 `-mkdir -p` 可以一次性创建多级目录。
